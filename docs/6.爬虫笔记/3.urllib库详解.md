## urllib库详解

#### **python内置的HTTP请求库**

- Urllib.request()   请求模块
- urllib.error    异常处理模块
- urllib.parse    url解析模块
- urllib.robotparser robots.txt 解析模块

#### **基本用法**

GET请求(实例)

```python
import urllib.request
res = urllib.request.urlopen('http://www.baidu.com')
print(res.read().decode())
```

POST请求(例子)

```python
import urllib.parse
import urllib.request
data = bytes(urllib.parse.urlencode({'name':'hello'}),encoding='utf-8')
res = urllib.request.urlopen('http://httpbin.org/post',data=data)
print(res.read().decode())
```

#### 获取图片并自动保存

```python
from urllib import request
request.urlretrieve(url='图片地址',filename='文件地址')
```

#### **设置超时问题**

正常

```python
import urllib.request
res = urllib.request.urlopen('http://httpbin.org/get',timeout=1)
print(res.read())
```

错误

```python
import socket
import urllib.request
import urllib.error
try:
    res = urllib.request.urlopen('http://httpbin.org/get',timeout=0.1)
except urllib.error.URLError as e:
    if isinstance(e.reason,socket.timeout):
        print('time out')
```

#### **响应**

```python
# 响应类型:<class 'http.client.HTTPResponse'>
# 状态码和响应头
import urllib.request
res = urllib.request.urlopen('http://www.baidu.com')
print(res.status)  # 状态码
print(res.getheaders()) # 全部响应头
print(res.getheader('Server'))
print(res.read().decode('utf-8'))  # 获取响应体内容
```

#### 请求

```python
import urllib.request
request = urllib.request.Request('http://www.baidu.com') # 生成一个对象
res = urllib.request.urlopen(request)
print(res)

# 增加参数和使用post请求
from urllib import request,parse
url = 'http://www.httpbin.org/post'
headers = {
    'User-Agent':'Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36',
    'Host':'httpbin.org'
}
dic = {
   'name':'Germey'

}
data = bytes(parse.urlencode(dic),encoding='utf8')
req = request.Request(url=url,data=data,headers=headers,method='POST')
res = request.urlopen(req)
print(res)

# header也可以使用这样
req.add_header('User-Agent','Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36',)

```

#### **代理**

```python
from urllib import request
proxy_header = request.ProxyHandler({
    'http':'http://127.0.0.1:8899',
    'https':'https://127.0.0.1:8899',
})
opener = request.build_opener(proxy_header)
res = opener.open('http://www.baidu.com')
print(res.read())
```

#### **异常处理**

```python
from urllib import request,error
try:
    res = request.urlopen('http://www.baidu222.top/11')
    print(res.read())
except error.HTTPError as e:
    print(e.reason,e.code,e.headers)
except error.URLError as e:
    print(e.reason)
else:
    print('xxxx')
```

#### **URL解析**

- 协议类型:scheme='http/https'
- allow_fragments:#号后的内容存放在哪里
- urlunparse:将内容上面返回的内容进行拼接的
- urljoin:对两个url进行拼接,以后面的url为标准,有就覆盖,没有就用前面的
- import urllib.robotparser :查看那些路径是可以访问的,那些事不可以访问的

```python
from urllib.parse import urlparse
result = urlparse('https://blog.csdn.net/leejeff/article/details/52935706')
print(result,type(result))
# ParseResult(scheme='https', netloc='blog.csdn.net', path='/leejeff/article/details/52935706', params='', query='', fragment='') <class 'urllib.parse.ParseResult'>
```

## 