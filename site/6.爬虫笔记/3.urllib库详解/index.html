<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    <link rel="canonical" href="http://www.haoqihan.top/6.爬虫笔记/3.urllib库详解/">
    <link rel="shortcut icon" href="../../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>urllib库的使用 - 学习笔记</title>
    <link href="../../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../../css/highlight.css">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../../js/jquery-3.2.1.min.js"></script>
    <script src="../../js/bootstrap-3.3.7.min.js"></script>
    <script src="../../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "urllib\u5e93\u8be6\u89e3", url: "#_top", children: [
              {title: "python\u5185\u7f6e\u7684HTTP\u8bf7\u6c42\u5e93", url: "#pythonhttp" },
              {title: "\u57fa\u672c\u7528\u6cd5", url: "#_1" },
              {title: "\u83b7\u53d6\u56fe\u7247\u5e76\u81ea\u52a8\u4fdd\u5b58", url: "#_2" },
              {title: "\u8bbe\u7f6e\u8d85\u65f6\u95ee\u9898", url: "#_3" },
              {title: "\u54cd\u5e94", url: "#_4" },
              {title: "\u8bf7\u6c42", url: "#_5" },
              {title: "\u4ee3\u7406", url: "#_6" },
              {title: "\u5f02\u5e38\u5904\u7406", url: "#_7" },
              {title: "URL\u89e3\u6790", url: "#url" },
          ]},
        ];

    </script>
    <script src="../../js/base.js"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
  <a name="_top"></a>
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="6.爬虫笔记/4.requests的基本使用方法/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="6.爬虫笔记/4.requests的基本使用方法/" class="btn btn-xs btn-link">
        requests库的使用
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="6.爬虫笔记/2.re模块的使用/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="6.爬虫笔记/2.re模块的使用/" class="btn btn-xs btn-link">
        re模块的使用
      </a>
    </div>
    
  </div>

    

    <h2 id="urllib">urllib库详解</h2>
<h4 id="pythonhttp"><strong>python内置的HTTP请求库</strong></h4>
<ul>
<li>Urllib.request()   请求模块</li>
<li>urllib.error    异常处理模块</li>
<li>urllib.parse    url解析模块</li>
<li>urllib.robotparser robots.txt 解析模块</li>
</ul>
<h4 id="_1"><strong>基本用法</strong></h4>
<p>GET请求(实例)</p>
<pre><code class="python">import urllib.request
res = urllib.request.urlopen('http://www.baidu.com')
print(res.read().decode())
</code></pre>

<p>POST请求(例子)</p>
<pre><code class="python">import urllib.parse
import urllib.request
data = bytes(urllib.parse.urlencode({'name':'hello'}),encoding='utf-8')
res = urllib.request.urlopen('http://httpbin.org/post',data=data)
print(res.read().decode())
</code></pre>

<h4 id="_2">获取图片并自动保存</h4>
<pre><code class="python">from urllib import request
request.urlretrieve(url='图片地址',filename='文件地址')
</code></pre>

<h4 id="_3"><strong>设置超时问题</strong></h4>
<p>正常</p>
<pre><code class="python">import urllib.request
res = urllib.request.urlopen('http://httpbin.org/get',timeout=1)
print(res.read())
</code></pre>

<p>错误</p>
<pre><code class="python">import socket
import urllib.request
import urllib.error
try:
    res = urllib.request.urlopen('http://httpbin.org/get',timeout=0.1)
except urllib.error.URLError as e:
    if isinstance(e.reason,socket.timeout):
        print('time out')
</code></pre>

<h4 id="_4"><strong>响应</strong></h4>
<pre><code class="python"># 响应类型:&lt;class 'http.client.HTTPResponse'&gt;
# 状态码和响应头
import urllib.request
res = urllib.request.urlopen('http://www.baidu.com')
print(res.status)  # 状态码
print(res.getheaders()) # 全部响应头
print(res.getheader('Server'))
print(res.read().decode('utf-8'))  # 获取响应体内容
</code></pre>

<h4 id="_5">请求</h4>
<pre><code class="python">import urllib.request
request = urllib.request.Request('http://www.baidu.com') # 生成一个对象
res = urllib.request.urlopen(request)
print(res)

# 增加参数和使用post请求
from urllib import request,parse
url = 'http://www.httpbin.org/post'
headers = {
    'User-Agent':'Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36',
    'Host':'httpbin.org'
}
dic = {
   'name':'Germey'

}
data = bytes(parse.urlencode(dic),encoding='utf8')
req = request.Request(url=url,data=data,headers=headers,method='POST')
res = request.urlopen(req)
print(res)

# header也可以使用这样
req.add_header('User-Agent','Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36',)

</code></pre>

<h4 id="_6"><strong>代理</strong></h4>
<pre><code class="python">from urllib import request
proxy_header = request.ProxyHandler({
    'http':'http://127.0.0.1:8899',
    'https':'https://127.0.0.1:8899',
})
opener = request.build_opener(proxy_header)
res = opener.open('http://www.baidu.com')
print(res.read())
</code></pre>

<h4 id="_7"><strong>异常处理</strong></h4>
<pre><code class="python">from urllib import request,error
try:
    res = request.urlopen('http://www.baidu222.top/11')
    print(res.read())
except error.HTTPError as e:
    print(e.reason,e.code,e.headers)
except error.URLError as e:
    print(e.reason)
else:
    print('xxxx')
</code></pre>

<h4 id="url"><strong>URL解析</strong></h4>
<ul>
<li>协议类型:scheme='http/https'</li>
<li>allow_fragments:#号后的内容存放在哪里</li>
<li>urlunparse:将内容上面返回的内容进行拼接的</li>
<li>urljoin:对两个url进行拼接,以后面的url为标准,有就覆盖,没有就用前面的</li>
<li>import urllib.robotparser :查看那些路径是可以访问的,那些事不可以访问的</li>
</ul>
<pre><code class="python">from urllib.parse import urlparse
result = urlparse('https://blog.csdn.net/leejeff/article/details/52935706')
print(result,type(result))
# ParseResult(scheme='https', netloc='blog.csdn.net', path='/leejeff/article/details/52935706', params='', query='', fragment='') &lt;class 'urllib.parse.ParseResult'&gt;
</code></pre>

<h2 id="_8"></h2>

  <br>
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="6.爬虫笔记/4.requests的基本使用方法/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="6.爬虫笔记/4.requests的基本使用方法/" class="btn btn-xs btn-link">
        requests库的使用
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="6.爬虫笔记/2.re模块的使用/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="6.爬虫笔记/2.re模块的使用/" class="btn btn-xs btn-link">
        re模块的使用
      </a>
    </div>
    
  </div>

    <br>
</div>

<footer class="col-md-12 wm-page-content">
      <p>
        <a href="https://github.com/haoqihan/learning/edit/master/docs/6.爬虫笔记/3.urllib库详解.md"><i class="fa fa-github"></i>
Edit on GitHub</a>
      </p>
  <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>